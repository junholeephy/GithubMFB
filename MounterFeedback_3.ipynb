{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataReader(object):\n",
    "    def __init__(self, Nw = 15):\n",
    "        self.Nw = Nw\n",
    "        self.Feature_DF_List = deque([],maxlen=Nw)\n",
    "        self.Component_Info_List = []\n",
    "        \n",
    "    \n",
    "    def Ready(self, json_data):\n",
    "        '''\n",
    "        Set Component Info. List\n",
    "        :param json_data\n",
    "        :return: None\n",
    "        '''\n",
    "        for ind in range(len(json_data['COMPONENT'])):\n",
    "            BLOCK_NO = json_data['COMPONENT'][ind]['BLOCK_NO']\n",
    "            REFERENCE = json_data['COMPONENT'][ind]['REFERENCE']\n",
    "            \n",
    "            self.Component_Info_List.append((BLOCK_NO,REFERENCE))\n",
    "            \n",
    "        return None\n",
    "    \n",
    "    def Step(self, json_data):\n",
    "        \n",
    "        feature_dict = {}\n",
    "        for ind, (BLOCK_NO,REFERENCE) in enumerate(self.Component_Info_List):\n",
    "#             print('comp',ind)\n",
    "            feature_pair = {}\n",
    "            for AXIS in ['LENGTH','WIDTH']:\n",
    "                feature_pair[AXIS] =  float(\n",
    "                    json_data['COMPONENT'][ind]['INSP_TYPE_VALUE'][0]['PADOVERHANG'][AXIS])\n",
    "            feature_dict[(BLOCK_NO,REFERENCE)] = feature_pair\n",
    "        \n",
    "        self.Feature_DF_List.append(pd.DataFrame(feature_dict).T)\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def PullFeatures(self, Axis, component_info, num = 1):\n",
    "        feature_list = []\n",
    "        for n in range(num):\n",
    "            feature_list.append(float(self.Feature_DF_List[n-num][Axis][component_info]))\n",
    "            \n",
    "        return feature_list\n",
    "    \n",
    "    def PullLastDataframe(self):\n",
    "        return self.Feature_DF_List[-1]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RankingDiscriminator(object):\n",
    "    def __init__(self,MaxOpNum = 20):\n",
    "        self.MaxOpNum = MaxOpNum\n",
    "        self.Component_Info_List = None\n",
    "        self.Score_DF = None\n",
    "    \n",
    "    def Ready(self, Component_Info_List):\n",
    "        self.Component_Info_List = Component_Info_List\n",
    "        \n",
    "        score_dict = {}\n",
    "        for (BLOCK_NO,REFERENCE) in self.Component_Info_List:\n",
    "            score_pair = {}\n",
    "            for AXIS in ['LENGTH','WIDTH']:\n",
    "                score_pair[AXIS] = 0\n",
    "            score_dict[(BLOCK_NO,REFERENCE)] = score_pair\n",
    "        \n",
    "        self.Score_DF = pd.DataFrame(score_dict).T\n",
    "        \n",
    "        return None\n",
    "        \n",
    "    def Step(self, Feature_DF):\n",
    "        for (BLOCK_NO,REFERENCE) in self.Component_Info_List:\n",
    "            for AXIS in ['LENGTH','WIDTH']:\n",
    "                self.Score_DF[AXIS][(BLOCK_NO,REFERENCE)] += float(Feature_DF[AXIS][(BLOCK_NO,REFERENCE)])\n",
    "        \n",
    "        return None\n",
    "       \n",
    "    def Rank(self, Current_State_DF):\n",
    "        high_ranked_components = {'LENGTH':[],'WIDTH':[]}\n",
    "        \n",
    "        length_score_df = self.Score_DF['LENGTH'].drop(Current_State_DF[Current_State_DF.LENGTH == 'ON'].index)\n",
    "        width_score_df = self.Score_DF['WIDTH'].drop(Current_State_DF[Current_State_DF.WIDTH == 'ON'].index)\n",
    "\n",
    "        high_ranked_components['LENGTH'] = list(length_score_df.sort_values(axis=0, ascending=False)[:self.MaxOpNum].index)\n",
    "        high_ranked_components['WIDTH'] = list(width_score_df.sort_values(axis=0, ascending=False)[:self.MaxOpNum].index)\n",
    "        \n",
    "        return high_ranked_components\n",
    "    \n",
    "    def ResetScore(self, Previous_State_DF, Current_State_DF):\n",
    "        for (BLOCK_NO,REFERENCE) in self.Component_Info_List:\n",
    "            for AXIS in ['LENGTH','WIDTH']:\n",
    "                if Previous_State_DF[AXIS][(BLOCK_NO,REFERENCE)] == 'ON' and \\\n",
    "                    Current_State_DF[AXIS][(BLOCK_NO,REFERENCE)] == 'OFF':\n",
    "                    self.Score_DF[AXIS][(BLOCK_NO,REFERENCE)] = 0\n",
    "        \n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import deque\n",
    "import scipy.stats as stats\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from scipy.signal import savgol_filter\n",
    "from math import floor\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "import pandas as pd\n",
    "\n",
    "from BOCD import bocd_meanNstd, NormalUnKnownMeanPrecision\n",
    "\n",
    "\n",
    "def HotellingT2(window):\n",
    "    '''\n",
    "    Find indexes of anomaly using Hotelling T-square method\n",
    "    calculate T2 score for each point & compare with calculated Upper-confidence-level.\n",
    "    if exceed, anomaly\n",
    "\n",
    "    :param window: data list\n",
    "    :return: indexes of anomaly\n",
    "    '''\n",
    "    alpha = 0.2  #FIXME : must be larger value\n",
    "    p = 1\n",
    "    m = len(window)\n",
    "    q = 2 * (m - 1) ** 2 / (3 * m - 4)\n",
    "\n",
    "    UCL = (m - 1) ** 2 * stats.beta.isf(alpha, p / 2, (q - p - 1) / 2) / m\n",
    "\n",
    "    mean = np.mean(window)\n",
    "    V = np.array([])\n",
    "    T2_list = []\n",
    "\n",
    "    for ind in range(m - 1):\n",
    "        V = np.append(V, window[ind + 1] - window[ind])\n",
    "\n",
    "    S = np.array([0.5 * V.transpose() @ V / (m - 1)])\n",
    "\n",
    "    for item in window:\n",
    "        delta = np.array(item) - np.array(mean)\n",
    "        T2 = delta * np.linalg.inv(np.array([S])) * delta\n",
    "        T2_list.append(T2)\n",
    "\n",
    "    anomaly = []\n",
    "    for ind, value in enumerate(T2_list):\n",
    "        if value > UCL:\n",
    "            anomaly.append(ind)\n",
    "\n",
    "    return anomaly\n",
    "\n",
    "class Operator(object):    \n",
    "    def __init__(self, Nw=15, Nomin=3, Nomax=20):\n",
    "        '''\n",
    "        :param Nw: window size for outlier\n",
    "        :param Nomin: min window size for waiting Mounter-FeedBack (MFB) reflection\n",
    "        :param Nomax: max window size for waiting Mounter-FeedBack (MFB) reflection\n",
    "        '''\n",
    "        \n",
    "        self.LastCPD = 0  # index\n",
    "        self.LastOP = 0  # index\n",
    "        self.LastSubOP = 0  # index\n",
    "        \n",
    "        # status : two status considered i.e. 'noFBapplied' & 'FBapplied'\n",
    "        self.status = 'noFBapplied'\n",
    "\n",
    "        # window size\n",
    "        self.Nw = Nw  # mentioned\n",
    "        self.Nomin = Nomin  # mentioned\n",
    "        self.Nomax = Nomax  # mentioned\n",
    "        self.Nstd = Nw  # mentioned\n",
    "\n",
    "        # data list\n",
    "        \n",
    "        self.data = []  # data list (FB applied list : collected data list if online production)\n",
    "\n",
    "        # data window\n",
    "        self.window = deque([], maxlen=self.Nw)  # Raw data list for calculating offset & for smoothing (Nw data)\n",
    "        self.window_for_compare = deque([], maxlen=self.Nw)  # Smoothed data list to compare threshold & current state\n",
    "\n",
    "        # Target & Threshold\n",
    "        self.Target = 0\n",
    "        self.offset_threshold = None\n",
    "\n",
    "        # Operation\n",
    "        self.sub_operation = False  # where or not already applied sub-operation, as sub-op applied only once right after CPD\n",
    "\n",
    "        # waiting step for reflection\n",
    "        self.wait_num = 0  # counting number for monitoring Mounter-FeedBack delay\n",
    "        self.abrupt_num = 0  # number counting low p-value point for Abrupt CPD\n",
    "        self.p = 0.05  # respective lower & upper p-value for Abrupt CPD\n",
    "        self.estimator = None  # Gaussian KDE for Abrupt CPD => p-value calculated based on the Gaussian KDE regressed distribution\n",
    "\n",
    "    def clear(self):\n",
    "        self.LastCPD = 0  # index\n",
    "        self.LastOP = 0  # index\n",
    "        self.LastSubOP = 0  # index\n",
    "        \n",
    "        # status : two status considered i.e. 'noFBapplied' & 'FBapplied'\n",
    "        self.status = 'noFBapplied'\n",
    "\n",
    "        # data list\n",
    "        self.data = []  # total data list (FB applied list : collected data list if online production)\n",
    "\n",
    "        # data window\n",
    "        self.window = deque([], maxlen=self.Nw)  # Raw data list for calculating offset & for smoothing (Nw data)\n",
    "        self.window_for_compare = deque([], maxlen=self.Nw)  # Smoothed data list to compare threshold & current state\n",
    "\n",
    "        # Target & Threshold\n",
    "        self.Target = 0\n",
    "        self.offset_threshold = None\n",
    "\n",
    "        # Operation\n",
    "        self.sub_operation = False  # where or not already applied sub-operation, as sub-op applied only once right after CPD\n",
    "\n",
    "        # waiting step for reflection\n",
    "        self.wait_num = 0  # counting number for monitoring Mounter-FeedBack delay\n",
    "        self.abrupt_num = 0  # number counting low p-value point for Abrupt CPD\n",
    "        self.estimator = None  # Gaussian KDE for Abrupt CPD => p-value calculated based on the Gaussian KDE regressed distribution\n",
    "\n",
    "        return None\n",
    "        \n",
    "    def _run_CPD(self):\n",
    "        '''\n",
    "        Check if change has occurred in the latest (No + Nw) data\n",
    "        :return: True/False, sequence point of CP\n",
    "        '''\n",
    "        # BOCD 가동\n",
    "        TimeSequence = self.Nw + len(self.data) - self.LastOP  # window size for detecting change-point\n",
    "\n",
    "        std = np.std(np.array(self.data[-TimeSequence:][:self.Nw]))  # Std calculation for BOCPD FIXME (:self.Nw)\n",
    "\n",
    "        mu0 = 0  # Prior on Gaussian mean. (A parameter of normal-gamma prior distribution)\n",
    "        gamma0 = 1  # (A parameter of normal-gamma prior distribution)\n",
    "        alpha0 = 1  # (A parameter of normal-gamma prior distribution)\n",
    "        beta0 = alpha0 * std ** 2  # \"sqrt(beta/alpha) = std\" (A parameter of normal-gamma prior distribution)\n",
    "\n",
    "        hazard = 1 / 50.0  # Hazard survival function assumes probability to be a CP for each data point. #FIXME (1/20.0 ??)\n",
    "        message = np.array([1])  # Iterative message calculated using previously collected data.\n",
    "\n",
    "        Data_list = []\n",
    "        RL_dist_list = []\n",
    "        Temp_RL_dist = np.zeros((TimeSequence, TimeSequence))\n",
    "\n",
    "        model = NormalUnKnownMeanPrecision(mu0, gamma0, alpha0, beta0)  # Data assumed be to a normal distribution.\n",
    "        # Case : Both of mean and std unknown\n",
    "        # BOCPD class called.\n",
    "\n",
    "        RL = []  # Run-Length distribution initial list\n",
    "        Start = []  # Estimated Change-Point starting point\n",
    "        cp_list = [0]  # Detected Change-Point sequence saved list\n",
    "\n",
    "        for ind, cont in enumerate(range(TimeSequence)):\n",
    "            Data_list.append(self.data[-TimeSequence + ind])\n",
    "            RL_dist, new_joint = bocd_meanNstd(data_list=Data_list, model=model,\n",
    "                                               hazard=hazard, Message=message)\n",
    "\n",
    "            message = new_joint  # each point sequential likelihood, or numerator of RL posterior distribution.\n",
    "            RL_dist_list.append(RL_dist)\n",
    "            Temp_RL_dist[ind, :ind + 1] = RL_dist[1:]  # RL distribution temporary saved as a element of a list\n",
    "\n",
    "            RL.append(np.argmax(\n",
    "                Temp_RL_dist[ind]))  # The highest probability corresponding sequence of RL posterior distribution\n",
    "            Start.append((ind, ind - RL[-1]))\n",
    "\n",
    "            if ind >= 1:\n",
    "                if Start[-1][1] != Start[-2][1]:\n",
    "                    if max(cp_list) > ind - RL[-1]:\n",
    "                        cp_list = cp_list[:-1]  # Remove the lastly added Change-Point\n",
    "                    else:\n",
    "                        cp_list.append(ind - RL[-1])  # Change-point Detected and append into the list\n",
    "\n",
    "        if not cp_list:  # If no FeedBack candidate found\n",
    "            return False, None\n",
    "        elif cp_list[-1] < self.Nw:  # Exclude a CP ahead of FeedBack operation applied sequence\n",
    "            return False, None\n",
    "        else:\n",
    "            for cp in cp_list[1:]:  # Exclude initial point (the point '0')\n",
    "                self.LastCPD = len(self.data) - TimeSequence + cp_list[-1]\n",
    "            return True, cp_list[-1]\n",
    "\n",
    "    def _is_within_threshold(self):\n",
    "        '''\n",
    "        Check if the smoothed data is inside the threshold\n",
    "        :return: True/ False ('True' if data lies within threshold )\n",
    "        '''\n",
    "        is_withinThreshold = False\n",
    "\n",
    "        # Outlier : Last Nw smoothed data must be the same sign\n",
    "        '''\n",
    "        check = 0\n",
    "        for smoothed in self.window_for_compare:\n",
    "            check += np.sign(smoothed)\n",
    "\n",
    "        if np.abs(check) != self.Nw:\n",
    "            is_withinThreshold = True  \n",
    "        '''\n",
    "        check = np.sign(self.window_for_compare[0])\n",
    "        for smoothed in self.window_for_compare:\n",
    "            if(check != np.sign(smoothed)):\n",
    "                is_withinThreshold = True; break; #FIXME (Non-same-sign which is anomaly ??)\n",
    "\n",
    "        # Outlier : Last Nw smoothed data must be out of threshold.\n",
    "        for smoothed in self.window_for_compare:\n",
    "            if np.abs(smoothed - self.Target) <= self.offset_threshold:\n",
    "                is_withinThreshold = True\n",
    "\n",
    "        return is_withinThreshold\n",
    "\n",
    "    def _do_operation(self):\n",
    "        '''\n",
    "        Apply operation & Set operation delay\n",
    "        OUTPUT : operation\n",
    "        '''\n",
    "        self.sub_operation = False\n",
    "\n",
    "        # Exclude anomaly before calculating offset by using Hotelling's T2\n",
    "        windowForAnomaly = self.window\n",
    "        anomaly = HotellingT2(windowForAnomaly)\n",
    "        for delete_ind, anomaly_ind in enumerate(anomaly):\n",
    "            del windowForAnomaly[anomaly_ind - delete_ind] # windowForAnomaly : Anomaly excluded window \n",
    "\n",
    "        # Calculate offset & operation\n",
    "        offset = np.mean(windowForAnomaly)\n",
    "        \n",
    "        # Append operation index\n",
    "        self.LastOP = len(self.data)\n",
    "        \n",
    "        return self.Target - offset\n",
    "\n",
    "\n",
    "    def _do_sub_operation(self):\n",
    "        '''\n",
    "        Apply sub-operation & Set sub-operation delay\n",
    "        OUTPUT : operation\n",
    "        '''\n",
    "        self.sub_operation = True  # number of sub operations\n",
    "\n",
    "        # Exclude anomaly before calculating offset by using Hotelling's T2\n",
    "        windowForAnomaly = self.data[max(self.LastCPD, self.LastOP):]\n",
    "        anomaly = HotellingT2(windowForAnomaly)\n",
    "        for delete_ind, anomaly_ind in enumerate(anomaly):\n",
    "            del windowForAnomaly[anomaly_ind - delete_ind] # windowForAnomaly : Anomaly excluded window \n",
    "\n",
    "        # Calculate offset & operation\n",
    "        offset = np.mean(windowForAnomaly)\n",
    "        \n",
    "        # Append sub-operation index\n",
    "        self.LastSubOP = len(self.data)\n",
    "        \n",
    "        self.clear()\n",
    "        \n",
    "        return self.Target - offset\n",
    "\n",
    "\n",
    "    def step(self, feature):\n",
    "        '''\n",
    "        MFB Loop\n",
    "        :param feature: offset data\n",
    "        :return: None\n",
    "        '''\n",
    "        # START\n",
    "        if self.status == 'noFBapplied':\n",
    "            self._put_feature(feature)\n",
    "\n",
    "            # Enough data ?\n",
    "            if len(self.data) - self.LastCPD < self.Nw:\n",
    "                return 0, None\n",
    "\n",
    "            # Check if lies within calculated threshold. If not, do operation.\n",
    "            if self._is_within_threshold():\n",
    "                if len(self.data) == self.Nw:\n",
    "                    self.clear()\n",
    "                    return 0, 'IN'\n",
    "                # If state is on target & stable, do one sseub-operation.\n",
    "                if not self.sub_operation: # \"False\" if no sub-operation from last CPD point. (As only one sub-op applied for one ADF-test steady-state)\n",
    "                    check_point = max(self.LastCPD, self.LastOP) #'op_list':not considered delay operation index list, 'CPD_list': BOCPD found CPD index list\n",
    "                    if (len(self.data) - check_point) >= self.Nw:  # There must be enough data after Op. or CPD.\n",
    "                        if adfuller(self.data[check_point:])[1] < 1e-6:  # Stable?\n",
    "                            return self._do_sub_operation(), 'SUB'\n",
    "                        if (len(self.data) - check_point) <= 3*self.Nw:\n",
    "                            self.clear()\n",
    "                            return 0, 'IN'\n",
    "                return 0, None\n",
    "            else:\n",
    "                self.estimator = stats.gaussian_kde(self.window)  # Set Gaussian KDE for Abrupt CPD.   # FIXME : minimum of delay given, then calculate the estimator\n",
    "                self.status = 'FBapplied'\n",
    "                return self._do_operation(), 'MAIN' # SG-filter smoothing is not consider anomaly # FIXME\n",
    "                \n",
    "        # Waiting for FB to be applied.\n",
    "        if self.status == 'FBapplied':\n",
    "            self._put_feature(feature)\n",
    "            self.wait_num += 1\n",
    "\n",
    "            # Abrupt CPD : repeating low p-value point or waiting enough fires BOCD\n",
    "            if self.estimator.integrate_box_1d(-np.Inf, feature) < self.p or \\\n",
    "                    self.estimator.integrate_box_1d(-np.Inf, feature) > 1 - self.p:\n",
    "                self.abrupt_num += 1\n",
    "\n",
    "            if self.wait_num >= self.Nomax:\n",
    "                self._run_CPD()  # CPD fired\n",
    "                self.wait_num = 0  # Reset self.wait_num\n",
    "                self.abrupt_num = 0  # Reset self.abrupt_num\n",
    "                self.status = 'noFBapplied'  # Reset self.status\n",
    "                return 0, None\n",
    "\n",
    "            elif self.abrupt_num >= self.Nomin:\n",
    "                self._run_CPD()  # CPD fired\n",
    "                self.wait_num = 0  # Reset self.wait_num\n",
    "                self.abrupt_num = 0  # Reset self.abrupt_num\n",
    "                self.status = 'noFBapplied'  # Reset self.status\n",
    "                return 0, None\n",
    "\n",
    "            else:\n",
    "                return 0, None\n",
    "            \n",
    "\n",
    "        \n",
    "    def _put_feature(self, feature):\n",
    "        '''\n",
    "        Get offset data\n",
    "        :param feature: offset data\n",
    "        :return: None\n",
    "        '''\n",
    "        # Append feature to data lists\n",
    "        self.data.append(feature)  # Collected total data\n",
    "        self.window.append(feature)  # Nw corresponding window size\n",
    "\n",
    "        # Initialize the threshold\n",
    "        if len(self.data) == self.Nstd:   # FIXME use once at the initial stage (put outside of the state stage)\n",
    "            self.offset_threshold = 0.5 * np.std(self.data)\n",
    "\n",
    "        # Data smoothing\n",
    "        if len(self.data) >= self.Nw:\n",
    "            savgol_result = savgol_filter(self.data[-self.Nw:], 2*floor((self.Nw-1)/2)+1, 3)\n",
    "            self.window_for_compare = savgol_result  ## compare threshold with sg-filter regressed line\n",
    "                    \n",
    "        # Reset the threshold\n",
    "        if (len(self.data) - self.LastCPD) % self.Nstd == 0:\n",
    "            buffer = self.data[-self.Nstd:]\n",
    "            STD = np.std(buffer)\n",
    "            if 0.7 * self.offset_threshold > STD or self.offset_threshold < 0.7 * STD:\n",
    "                self.offset_threshold = 0.5 * STD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MounterSimulator(object):\n",
    "    def __init__(self, json_data, NumList = 5):\n",
    "        self.operation_buffer = np.array([[0,0]]*NumList)\n",
    "        self.operation = copy.deepcopy(self.operation_buffer)\n",
    "        self.delay = np.array([[[0],[0]]]*NumList)\n",
    "        self.NumList = NumList \n",
    "        \n",
    "        pcb_info = json_data\n",
    "        pcb_info['COMPONENT'] = pcb_info['COMPONENT'][:self.NumList]\n",
    "        self.PCB_INFO = pcb_info\n",
    "        \n",
    "        \n",
    "    def PLANT(self, FEEDBACK_INFO, json_data):\n",
    "        self.PCB_INFO = json_data\n",
    "        for component_index in range(self.NumList):\n",
    "            for axis_ind,AXIS in enumerate(['AdjustX','AdjustY']):\n",
    "                if FEEDBACK_INFO['OFFSETLIST'][component_index][AXIS] != 0:\n",
    "                    self.delay[component_index][axis_ind] = round(np.random.exponential(scale=2))+1\n",
    "                    self.delay[component_index][axis_ind] = 1\n",
    "                    self.operation_buffer[component_index][axis_ind] \\\n",
    "                        = FEEDBACK_INFO['OFFSETLIST'][component_index][AXIS]\n",
    "\n",
    "                    \n",
    "        self.delay -= 1\n",
    "        \n",
    "        for component_index in range(self.NumList):\n",
    "            for axis_ind, AXIS in enumerate(['LENGTH','WIDTH']):\n",
    "                if self.delay[component_index][axis_ind] == 0 :\n",
    "                    self.operation[component_index][axis_ind] += float(\n",
    "                        self.operation_buffer[component_index][axis_ind])\n",
    "  \n",
    "                self.PCB_INFO['COMPONENT'][component_index]['INSP_TYPE_VALUE'][0]['PADOVERHANG'][AXIS] \\\n",
    "                        = str(float(\n",
    "                        self.PCB_INFO['COMPONENT'][component_index]['INSP_TYPE_VALUE'][0]['PADOVERHANG'][AXIS])\n",
    "                        + self.operation[component_index][axis_ind])\n",
    "      \n",
    "        return self.PCB_INFO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MounterFeedback(object):\n",
    "    def __init__(self, MaxOpNum = 20, Nw = 15):\n",
    "        self.MaxOpNum = MaxOpNum\n",
    "        self.Nw = Nw\n",
    "        \n",
    "        self.Operator_DF = None\n",
    "        self.Operation_DF = None\n",
    "        self.Previous_State_DF = None\n",
    "        self.Current_State_DF = None\n",
    "        \n",
    "        self.Component_Info_List = []\n",
    "        \n",
    "        self.DataReader = DataReader(Nw=Nw)\n",
    "        self.RankingDiscriminator = RankingDiscriminator(MaxOpNum = MaxOpNum)\n",
    "        \n",
    "        self.state = 'noInitialShifting'\n",
    "        \n",
    "    def Ready(self, json_data):\n",
    "        '''\n",
    "        Initialize MFB algorithm & Ready for feedback\n",
    "        :param json_data\n",
    "        :return: None\n",
    "        '''\n",
    "        self.DataReader.Ready(json_data)\n",
    "        self.RankingDiscriminator.Ready(self.DataReader.Component_Info_List)\n",
    "        self.Component_Info_List = self.DataReader.Component_Info_List\n",
    "        \n",
    "        # Init operator_df & operation_df\n",
    "        \n",
    "        operator_dict = {}\n",
    "        current_state_dict = {}\n",
    "        previous_state_dict = {}\n",
    "        operation_dict = {}\n",
    "        \n",
    "        for (BLOCK_NO,REFERENCE) in self.Component_Info_List:        \n",
    "            operator_pair = {}\n",
    "            current_state_pair = {}\n",
    "            previous_state_pair = {}\n",
    "            operation_pair = {}\n",
    "            for AXIS in ['LENGTH','WIDTH']:\n",
    "                operator_pair[AXIS] = Operator(Nw=15, Nomin=3, Nomax=20)\n",
    "                current_state_pair[AXIS] = 'OFF'\n",
    "                previous_state_pair[AXIS] = 'OFF'\n",
    "                operation_pair[AXIS] = (0, None)\n",
    "                \n",
    "            operator_dict[(BLOCK_NO,REFERENCE)] = operator_pair\n",
    "            current_state_dict[(BLOCK_NO,REFERENCE)] = current_state_pair\n",
    "            previous_state_dict[(BLOCK_NO,REFERENCE)] = previous_state_pair\n",
    "            operation_dict[(BLOCK_NO,REFERENCE)] = operation_pair\n",
    "            \n",
    "        self.Operator_DF = pd.DataFrame(operator_dict).T\n",
    "        self.Current_State_DF = pd.DataFrame(current_state_dict).T\n",
    "        self.Previous_State_DF = pd.DataFrame(previous_state_dict).T\n",
    "        self.Operation_DF = pd.DataFrame(operation_dict).T\n",
    "        \n",
    "        \n",
    "        \n",
    "    def ReturnFeedbackInfo(self):\n",
    "        FEEDBACK_INFO = {\"FeedbackType\": \"PLACEDLOCATIONOFFSET\",\n",
    "                         \"SeqID\": json_data[\"ASST_SEQNO\"],\n",
    "                         \"Time\": json_data[\"END_DATE_TIME\"],\n",
    "                         \"MachineName\": json_data[\"MACHINE_NM\"],\n",
    "                         \"LaneNo\": json_data[\"LANE_NO\"],\n",
    "                         \"Target\": '1',\n",
    "                         \"NumList\": len(json_data[\"COMPONENT\"]),\n",
    "                         \"OFFSETLIST\": []}\n",
    "        \n",
    "\n",
    "        for (BLOCK_NO,REFERENCE) in self.Component_Info_List:  \n",
    "            FEEDBACK_INFO[\"OFFSETLIST\"].append(\n",
    "                {'BLOCK_NO': BLOCK_NO, 'REFERENCE': REFERENCE,\n",
    "                 'AdjustX': self.Operation_DF['LENGTH'][(BLOCK_NO,REFERENCE)][0],\n",
    "                 'AdjustY': self.Operation_DF['WIDTH'][(BLOCK_NO,REFERENCE)][0]})\n",
    "                \n",
    "        return FEEDBACK_INFO\n",
    "        \n",
    "                \n",
    "    def Step(self, json_data):\n",
    "        '''\n",
    "        param json_data\n",
    "        return: feedback information as dictionary\n",
    "        '''\n",
    "        self.DataReader.Step(json_data)\n",
    "        \n",
    "        self.RankingDiscriminator.Step(self.DataReader.PullLastDataframe())\n",
    "        \n",
    "        high_ranked_components = self.RankingDiscriminator.Rank(self.Current_State_DF)\n",
    "        \n",
    "        \n",
    "        if len(self.DataReader.Feature_DF_List) < self.Nw :\n",
    "            return self.ReturnFeedbackInfo()\n",
    "        \n",
    "        for AXIS in ['LENGTH','WIDTH']:\n",
    "            for (BLOCK_NO,REFERENCE) in high_ranked_components[AXIS]:\n",
    "                self.Current_State_DF[AXIS][(BLOCK_NO,REFERENCE)] = 'ON'\n",
    "                \n",
    "                \n",
    "        for AXIS in ['LENGTH','WIDTH']:\n",
    "            for (BLOCK_NO,REFERENCE) in self.Component_Info_List:\n",
    "                if self.Current_State_DF[AXIS][(BLOCK_NO,REFERENCE)] == 'ON':\n",
    "                    if self.Previous_State_DF[AXIS][(BLOCK_NO,REFERENCE)] == 'OFF':\n",
    "#                         if (BLOCK_NO,REFERENCE)==('1','C10'):\n",
    "#                             print('asdasdasdaasfads')\n",
    "                        ResentData = self.DataReader.PullFeatures(\n",
    "                            AXIS,(BLOCK_NO,REFERENCE),num=self.Nw)[:-1]\n",
    "                        self.Operator_DF[AXIS][(BLOCK_NO,REFERENCE)].data += ResentData\n",
    "                        self.Operator_DF[AXIS][(BLOCK_NO,REFERENCE)].window += ResentData\n",
    "                        \n",
    "                        operation = self.Operator_DF[AXIS][(BLOCK_NO,REFERENCE)].step(\n",
    "                            self.DataReader.PullFeatures(AXIS,(BLOCK_NO,REFERENCE))[0])\n",
    "                        \n",
    "                        self.Operation_DF[AXIS][(BLOCK_NO,REFERENCE)] = operation\n",
    "                    \n",
    "                    else:\n",
    "                        operation = self.Operator_DF[AXIS][(BLOCK_NO,REFERENCE)].step(\n",
    "                            self.DataReader.PullFeatures(AXIS,(BLOCK_NO,REFERENCE))[0])\n",
    "                        \n",
    "                        self.Operation_DF[AXIS][(BLOCK_NO,REFERENCE)] = operation\n",
    "                        \n",
    "#                     if (BLOCK_NO,REFERENCE)==('1','C10'):\n",
    "#                         print('^^')\n",
    "#                         print(self.Operator_DF[AXIS][(BLOCK_NO,REFERENCE)].data)\n",
    "                        \n",
    "                else:\n",
    "                    self.Operation_DF[AXIS][(BLOCK_NO,REFERENCE)] = (0, None)\n",
    "        \n",
    "        \n",
    "        self.Previous_State_DF = self.Current_State_DF.copy()\n",
    "        \n",
    "        self.RankingDiscriminator.ResetScore(self.Previous_State_DF, self.Current_State_DF)\n",
    "        \n",
    "        for AXIS in ['LENGTH','WIDTH']:\n",
    "            for (BLOCK_NO,REFERENCE) in self.Component_Info_List:\n",
    "                if self.Operation_DF[AXIS][(BLOCK_NO,REFERENCE)][1] == 'SUB' or \\\n",
    "                  self.Operation_DF[AXIS][(BLOCK_NO,REFERENCE)][1] == 'IN':\n",
    "                    self.Current_State_DF[AXIS][(BLOCK_NO,REFERENCE)] = 'OFF'\n",
    "        \n",
    "        \n",
    "        return self.ReturnFeedbackInfo()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'FEEDBACK_INFO' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-b333d58373a6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     37\u001b[0m                   '\\n',MFB.Operation_DF['WIDTH'][('1','C10')])\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m         \u001b[0mjson_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmounter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPLANT\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFEEDBACK_INFO\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m         \u001b[0mFEEDBACK_INFO\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMFB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjson_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'FEEDBACK_INFO' is not defined"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    import os\n",
    "    import json\n",
    "    import copy\n",
    "    \n",
    "    Data_temp = pd.read_csv(\"C:/Users/T5402/Downloads/n1_test_500k.txt\", sep=',')\n",
    "\n",
    "    \n",
    "    json_directory_path = 'C:/Users/T5402/Desktop/merge_samples2'\n",
    "    json_file_list = os.listdir(json_directory_path)\n",
    "    \n",
    "    f = open(json_directory_path+'/'+json_file_list[0],'r')\n",
    "    json_data = dict(json.load(f))\n",
    "    \n",
    "    \n",
    "    NumList = 4\n",
    "    TimeSequence = 450\n",
    "    \n",
    "    MFB = MounterFeedback(MaxOpNum=1)\n",
    "    MFB.Ready(json_data)\n",
    "    mounter = MounterSimulator(json_data, NumList = NumList )\n",
    "    \n",
    "    raw = []\n",
    "    data1 = []\n",
    "    main = []\n",
    "    sub = []\n",
    "    \n",
    "    for i, file_name in enumerate(json_file_list[50:TimeSequence]):\n",
    "        f = open(json_directory_path+'/'+file_name,'r')\n",
    "        json_data = dict(json.load(f))\n",
    "        raw.append(float(json_data['COMPONENT'][1]['INSP_TYPE_VALUE'][0]['PADOVERHANG']['WIDTH']))\n",
    "\n",
    "        if i > 10 and MFB.Operation_DF['WIDTH'][('1','C10')][1] !=  None\\\n",
    "            and MFB.Operation_DF['WIDTH'][('1','C10')][1] !=  'IN':\n",
    "            print('====================\\npcb seq no',i)\n",
    "            print(MFB.Current_State_DF['WIDTH'][('1','C10')],\n",
    "                  '\\n',MFB.Operation_DF['WIDTH'][('1','C10')])\n",
    "\n",
    "        json_data = mounter.PLANT(FEEDBACK_INFO, json_data)\n",
    "        FEEDBACK_INFO = MFB.Step(json_data)\n",
    "        \n",
    "        if MFB.Operation_DF['WIDTH'][('1','C10')][1] == 'MAIN':\n",
    "            main.append(i)\n",
    "        if MFB.Operation_DF['WIDTH'][('1','C10')][1] == 'SUB':\n",
    "            sub.append(i)\n",
    "            \n",
    "        data1.append(float(\n",
    "            mounter.PCB_INFO['COMPONENT'][1]['INSP_TYPE_VALUE'][0]['PADOVERHANG']['WIDTH']))\n",
    "\n",
    "    \n",
    "    RMS_before_FB = round(np.sqrt(sum((np.array(raw) - np.zeros(len(raw))) ** 2) / len(raw)),2)\n",
    "    RMS_after_FB = round(np.sqrt(sum((np.array(data1) - np.zeros(len(data1))) ** 2) / len(data1)),2)\n",
    "    \n",
    "    print('RMS_before_FB\\t: ',RMS_before_FB)\n",
    "    print('RMS_after_FB\\t: ',RMS_after_FB)\n",
    "    \n",
    "    fit, (ax1) = plt.subplots(nrows=1, ncols=1, figsize=(20, 5))\n",
    "    ax1.grid(True)\n",
    "    ax1.plot(raw[:], 'grey')\n",
    "    ax1.plot(data1[:], 'blue')\n",
    "    ax1.axhline(0, linestyle='--', color='grey')\n",
    "    for i in main:\n",
    "        ax1.axvline(i, color = 'green', linewidth = 1, linestyle = '--')\n",
    "    for i in sub:\n",
    "        ax1.axvline(i, color = 'red', linewidth = 1, linestyle = '--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sdf\n"
     ]
    }
   ],
   "source": [
    "print(str('sdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    import os\n",
    "    import json\n",
    "    import copy\n",
    "    \n",
    "    Data_temp = pd.read_csv(\"C:/Users/T5402/Downloads/n1_test_500k.txt\", sep=',')\n",
    "\n",
    "    Pad_Temp = Data_temp[(Data_temp.Array_index == 2) & (Data_temp.Component_Name == 'R12')]\n",
    "    PadOff_X = np.array(Pad_Temp.PAD_Length_offset / 1000.0)[500:]\n",
    "    PadOff_Y = np.array(Pad_Temp.PAD_Width_offset / 1000.0)[500:]\n",
    "    \n",
    "    \n",
    "    json_directory_path = 'C:/Users/T5402/Desktop/merge_samples2'\n",
    "    json_file_list = os.listdir(json_directory_path)\n",
    "    \n",
    "    f = open(json_directory_path+'/'+json_file_list[0],'r')\n",
    "    json_data = copy.deepcopy(json.load(f))\n",
    "    \n",
    "    \n",
    "    for i in range(1000):\n",
    "        for j in range(4):\n",
    "            json_data['COMPONENT'][j]['INSP_TYPE_VALUE'][0]['PADOVERHANG']['LENGTH'] = str(PadOff_X[i]+np.random.normal(0,10))\n",
    "            json_data['COMPONENT'][j]['INSP_TYPE_VALUE'][0]['PADOVERHANG']['WIDTH'] = str(PadOff_Y[i]+np.random.normal(0,10))\n",
    "        with open('C:/Users/T5402/Desktop/merge_samples2/merge_sample'+str(i)+'.json', 'w') as make_file:\n",
    "            json.dump(json_data, make_file, indent=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
